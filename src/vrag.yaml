
# Settings for LLM model
  llm_name: 'Llama 3.2'
  llm_path: './models/Llama-3.2-3B-Instruct'
  llm_device: 'mps'
  #source: https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/inference/local_inference/chat_completion/chats.json
  llm_system_prompt: "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."
  

# Settings for vector store
  vs_embeddings_model_name: 'all-mpnet-base-v2'
  vs_embeddings_model_path: './models/sentence-transformers/all-mpnet-base-v2'
  vs_pdf_documents_folder: './documents'
  vs_output_folder: './vectorstore/database'
  vs_chunk_size: 1000
  vs_chunk_overlap: 50

#Settings for wake word detection
  ww_model_path: 'models/MIT-ast-finetuned-speech-commands-v2'
  ww_model_device: 'mps'
  ww_wake_word: 'seven'
  ww_prob_threshold: 0.5
  ww_chunk_length: 2.0
  ww_stream_chunk: 0.25
  ww_debug: False

#Settings for auotmatic speech recognition
  asr_model_path: './models/whisper-base'
  asr_model_device: 'mps'
  asr_chunk_length: 5.0
  asr_stream_chunk_s: 1.0
  asr_max_new_tokens: 128

#Settings for Retrieval Augmented Generation
  rag_top_k: 10
  rag_top_p: 0.9
  rag_repition_penalty: 1
  rag_streaming: True
  rag_temperature: 0.1
  rag_max_new_tokens: 200
  rag_do_sample: True 
  rag_retriever_documents: 7
  rag_debug: False

#Settings for Text to Speech Model
  tts_model_path: './models/SpeechT5'
  tts_hifigan_path: './models/SpeechT5HiFiGAN'
  tts_speaker_embeddings: './models/SpeechT5/speaker1.pt'
  tts_sampling_rate: 16000
  tts_word_per_utterance: 10


